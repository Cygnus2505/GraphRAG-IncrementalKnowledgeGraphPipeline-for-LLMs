# Phase 1: Delta to JSONL Export Configuration

delta {
  # Path to your HW2 Delta Lake warehouse
  # You can override this with command-line argument: --delta-path <path>
  warehouse-path = "C:/Users/harsh/IdeaProjects/Cs441-hw2-rag/out/delta-tables/warehouse/rag.db"
  
  # Table name within the warehouse (the main chunks table from HW2)
  # Based on verification, your HW2 has a single "chunks" table with all the data
  chunks-table = "chunks"
  doc-normalized-table = "doc_normalized"  # Optional, may not exist
}

output {
  # Output path for JSONL files
  # You can override this with command-line argument: --output-path <path>
  path = "./data/chunks.jsonl"
  
  # Output format: "json" produces JSONL (one JSON object per line)
  format = "json"
  
  # Number of output files (partitions)
  # Set to 1 for single file, or higher for parallel processing
  num-partitions = 1
  
  # Compression: "none", "gzip", "snappy", "lz4"
  compression = "none"
}

spark {
  app-name = "DeltaToJsonlExport"
  master = "local[*]"  # Use all available cores locally
  
  # Log level: ALL, DEBUG, INFO, WARN, ERROR, OFF
  log-level = "WARN"
}

